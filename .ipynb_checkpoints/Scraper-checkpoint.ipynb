{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51d49d0",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d449ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import pandas_profiling as pp\n",
    "import random\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib as mpl\n",
    "import mplsoccer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c634499e",
   "metadata": {},
   "source": [
    "### Setting directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fef012",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"..\"\n",
    "data_dir = os.path.join(base_dir,\"data\")\n",
    "data_dir_fbref = os.path.join(base_dir,\"data\",\"fbref\")\n",
    "img_dir = os.path.join(base_dir,\"image\")\n",
    "fig_dir = os.path.join(base_dir, \"image\", \"fig\")\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(data_dir_fbref, exist_ok=True)\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(fig_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170f0c5",
   "metadata": {},
   "source": [
    "### Creating league dictionaries and relevant lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ed2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "league_dict = {\n",
    "    'Premier-League': '9',\n",
    "    'Ligue-1': '13',\n",
    "    'Bundesliga': '20',\n",
    "    'Serie-A': '11',\n",
    "    'La-Liga': '12',\n",
    "    'Major-League-Soccer': '22',\n",
    "    'Big-5-European-Leagues': 'Big5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2501beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "league_names = ['Premier-League', 'Ligue-1', 'Bundesliga',\n",
    "                'Serie-A', 'La-Liga',\n",
    "                'Major-League-Soccer', 'Big-5-European-Leagues']\n",
    "\n",
    "seasons = ['2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022']\n",
    "\n",
    "folders = ['raw', 'engineered', 'reference']\n",
    "\n",
    "data_type = ['goalkeeper', 'outfield', 'team']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51f036",
   "metadata": {},
   "source": [
    "### Creating the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91fe7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the data directory structure\n",
    "for folder in folders:\n",
    "    path = os.path.join(data_dir_fbref, folder)\n",
    "    #print(path)\n",
    "    if not os.path.exists(path):\n",
    "        #print(path)\n",
    "        os.mkdir(path)\n",
    "    for data_types in data_type:\n",
    "        path = os.path.join(data_dir_fbref, folder, data_types)\n",
    "        #print(path)\n",
    "        if not os.path.exists(path):\n",
    "            #print(\"Here\")\n",
    "            os.mkdir(path)\n",
    "        for league in league_names:\n",
    "            path = os.path.join(data_dir_fbref, folder, data_types, league)\n",
    "            #print(path)\n",
    "            if not os.path.exists(path):\n",
    "                #print(\"here2\")\n",
    "                os.mkdir(path)\n",
    "            for season in seasons:\n",
    "                path = os.path.join(data_dir_fbref, folder, data_types, league, season)\n",
    "                #print(path)\n",
    "                if not os.path.exists(path):\n",
    "                    os.mkdir(path)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02b712",
   "metadata": {},
   "source": [
    "### Function to get outfield players data from FBRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7796392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for scraping a defined season and competition of FBref player data\n",
    "def get_fbref_player_stats(lst_league_names, lst_seasons):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to scrape player stats from FBref.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ## Define list of league names\n",
    "    league_names_long = lst_league_names\n",
    "    \n",
    "    \n",
    "    ## Define seasons to scrape\n",
    "    seasons = lst_seasons\n",
    "    \n",
    "    ## Scrape information for each player\n",
    "    for season in seasons:\n",
    "\n",
    "        ### Print message\n",
    "        print(f'Scraping started for the {season} season...')\n",
    "\n",
    "        ### Loop through leagues\n",
    "        for league_name_long in league_names_long:\n",
    "            \n",
    "            #### Determine league short name from the league names dictionary\n",
    "            league_name_short = [v for k,v in dict_league_names.items() if k == league_name_long][0]\n",
    "            \n",
    "            #### Save Player URL List (if not already saved)\n",
    "            if not os.path.exists(os.path.join(data_dir_fbref + f'/raw/outfield/{league_name_long}/{season}/fbref_outfield_player_stats_{league_name_long}_{season}_latest.csv')):\n",
    "\n",
    "                ##### Scraping\n",
    "\n",
    "                ##### Print statement\n",
    "                print(f'Scraping started for player stats data for {league_name_long} league for the {season} season...')\n",
    "\n",
    "                ##### Standard stats\n",
    "                print(f'Scraping Standard stats...')\n",
    "                url_std_stats = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fstats%2Fplayers%2F{season}-{league_name_long}&div=div_stats_standard'\n",
    "                df_std_stats = pd.read_html(url_std_stats, header=1)[0]\n",
    "\n",
    "\n",
    "                ##### Shooting stats\n",
    "                print(f'Scraping Shooting stats...')\n",
    "                url_shooting = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fshooting%2Fplayers%2F{season}-{league_name_long}&div=div_stats_shooting'\n",
    "                df_shooting = pd.read_html(url_shooting, header=1)[0]\n",
    "\n",
    "                ##### Passing stats\n",
    "                print(f'Scraping Passing stats...')\n",
    "                url_passing = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fpassing%2Fplayers%2F{season}-{league_name_long}&div=div_stats_passing'\n",
    "                df_passing = pd.read_html(url_passing, header=1)[0]\n",
    "\n",
    "                ##### Pass Types stats\n",
    "                print(f'Scraping Pass Types stats...')\n",
    "                url_passing_types = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fpassing_types%2Fplayers%2F{season}-{league_name_long}&div=div_stats_passing_types'\n",
    "                df_passing_types = pd.read_html(url_passing_types, header=1)[0]\n",
    "\n",
    "                ##### Goals and Shot Creation stats\n",
    "                print(f'Scraping Goals and Shot Creation stats...')\n",
    "                url_gca = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fgca%2Fplayers%2F{season}-{league_name_long}&div=div_stats_gca'\n",
    "                df_gca = pd.read_html(url_gca, header=1)[0]\n",
    "\n",
    "                ##### Defensive Actions stats\n",
    "                print(f'Scraping Defensive Actions stats...')\n",
    "                url_defense = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fdefense%2Fplayers%2F{season}-{league_name_long}&div=div_stats_defense'\n",
    "                df_defense = pd.read_html(url_defense, header=1)[0]\n",
    "\n",
    "                ##### Possession stats\n",
    "                print(f'Scraping Possession stats...')\n",
    "                url_possession = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fpossession%2Fplayers%2F{season}-{league_name_long}&div=div_stats_possession'\n",
    "                df_possession = pd.read_html(url_possession, header=1)[0]\n",
    "\n",
    "                ##### Playing Time stats\n",
    "                print(f'Scraping Playing Time stats...')\n",
    "                url_playing_time = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fplayingtime%2Fplayers%2F{season}-{league_name_long}&div=div_stats_playing_time'\n",
    "                df_playing_time = pd.read_html(url_playing_time, header=1)[0]\n",
    "\n",
    "                ##### Miscellaneous stats\n",
    "                print(f'Scraping Miscellaneous stats...')\n",
    "                url_misc = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fmisc%2Fplayers%2F{season}-{league_name_long}&div=div_stats_misc'\n",
    "                df_misc = pd.read_html(url_misc, header=1)[0]\n",
    "\n",
    "                ##### Concatenate defined individual DataFrames\n",
    "                \n",
    "                ####### Define DataFrames to be concatenated side-by-side (not all of them)\n",
    "                lst_dfs = [df_std_stats, df_shooting, df_passing, df_passing_types, df_gca, df_defense, df_possession]\n",
    "\n",
    "                ###### Concatenate DataFrames side-by-side (indicated in list above)\n",
    "                df_all = pd.concat(lst_dfs, axis=1)\n",
    "\n",
    "                ###### Drop duplicate columns\n",
    "                df_all = df_all.loc[:,~df_all.columns.duplicated()]\n",
    "\n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "                \n",
    "                ##### Left join defined individual DataFrames\n",
    "                \n",
    "                ####### Define join conditions\n",
    "                conditions_join = ['Player', 'Nation', 'Pos', 'Squad', 'Comp']\n",
    "\n",
    "                ###### Left join Playing Time data\n",
    "                df_all = pd.merge(df_all, df_playing_time, left_on=conditions_join, right_on=conditions_join, how='left')\n",
    "\n",
    "                ###### Remove duplicate columns after join (contain '_y') and remove '_x' suffix from kept columns\n",
    "                df_all = df_all[df_all.columns.drop(list(df_all.filter(regex='_y')))]\n",
    "                df_all.columns = df_all.columns.str.replace('_x','')\n",
    "                \n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "\n",
    "                ###### Left join Misc data\n",
    "                df_all = pd.merge(df_all, df_misc, left_on=conditions_join, right_on=conditions_join, how='left')\n",
    "\n",
    "                ###### Remove duplicate columns after join (contain '_y') and remove '_x' suffix from kept columns\n",
    "                df_all = df_all[df_all.columns.drop(list(df_all.filter(regex='_y')))]\n",
    "                df_all.columns = df_all.columns.str.replace('_x','')\n",
    "                \n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "                \n",
    "                \n",
    "                ##### Engineer DataFrames\n",
    "                \n",
    "                ###### Take first two digits of age - fixes current season issue with extra values\n",
    "                df_all['Age'] = df_all['Age'].astype(str).str[:2]\n",
    "                \n",
    "                ###### Create columns for league code and season\n",
    "                df_all['League Name'] = league_name_long\n",
    "                df_all['League ID'] = league_name_short\n",
    "                df_all['Season'] = season              \n",
    "\n",
    "                ###### Drop duplicates\n",
    "                df_all = df_all.drop_duplicates()\n",
    "\n",
    "                \n",
    "                ##### Save DataFrame\n",
    "                df_all.to_csv(data_dir_fbref + f'/raw/outfield/{league_name_long}/{season}/fbref_outfield_player_stats_{league_name_long}_{season}_latest.csv', index=None, header=True, encoding='utf-8')        \n",
    "                \n",
    "                ##### Export a copy to the 'archive' subfolder, including the date\n",
    "                #df_all.to_csv(data_dir_fbref + f'/raw/outfield/{league_name_long}/{season}/archive/fbref_outfield_player_stats_{league_name_long}_{season}_last_updated_{today}.csv', index=None, header=True, encoding='utf-8')        \n",
    "                \n",
    "                \n",
    "                ##### Print statement for league and season\n",
    "                print(f'All player stats data for the {league_name_long} league for {season} season scraped and saved.')\n",
    "             \n",
    "            \n",
    "            #### Load player stats data (if already saved)\n",
    "            else:\n",
    "\n",
    "                ##### Print statement\n",
    "                print(f'Player stats data for the {league_name_long} league for the {season} season already saved as a CSV file.')         \n",
    "\n",
    "                \n",
    "    ## Unify individual CSV files as a single DataFrame\n",
    "    \n",
    "    ### Show files in directory\n",
    "    all_files = glob.glob(os.path.join(data_dir_fbref + f'/raw/outfield/*/*/fbref_outfield_player_stats_*_*_latest.csv'))\n",
    "    \n",
    "    ### Create an empty list of Players URLs\n",
    "    lst_player_stats_all = []\n",
    "\n",
    "    ### Loop through list of files and read into temporary DataFrames\n",
    "    for filename in all_files:\n",
    "        df_temp = pd.read_csv(filename, index_col=None, header=0)\n",
    "        lst_player_stats_all.append(df_temp)\n",
    "\n",
    "    ### Concatenate the files into a single DataFrame\n",
    "    df_fbref_player_stats_all = pd.concat(lst_player_stats_all, axis=0, ignore_index=True)\n",
    "    \n",
    "    ### Drop header row of each concatenated  DataFrame (contains 'Rk', 'Rk' column)\n",
    "    df_fbref_player_stats_all = df_fbref_player_stats_all[~df_fbref_player_stats_all['Rk'].str.contains('Rk')]\n",
    "    \n",
    "    ### Drop 'Rk' column\n",
    "    df_fbref_player_stats_all = df_fbref_player_stats_all.drop(['Rk'], axis=1)\n",
    "    \n",
    "    ### Reset index\n",
    "    #df_fbref_player_stats_all = df_fbref_player_stats_all.reset_index()\n",
    "    \n",
    "    ### Sort DataFrame\n",
    "    df_fbref_player_stats_all = df_fbref_player_stats_all.sort_values(['League Name', 'Season', 'Player'], ascending=[True, True, True])\n",
    "\n",
    "    \n",
    "    ## Export DataFrame\n",
    "    \n",
    "    ###\n",
    "    df_fbref_player_stats_all.to_csv(data_dir_fbref + f'/raw/outfield/fbref_outfield_player_stats_combined_latest.csv', index=None, header=True, encoding='utf-8')\n",
    "    \n",
    "    ### Save a copy to archive folder (dated)\n",
    "    #df_fbref_player_stats_all.to_csv(data_dir_fbref + f'/raw/outfield/archive/fbref_outfield_player_stats_combined_last_updated_{today}.csv', index=None, header=True, encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    ## Distinct number of players\n",
    "    total_players = df_fbref_player_stats_all['Player'].nunique()\n",
    "\n",
    "\n",
    "    ## Print statement\n",
    "    print(f'Player stats DataFrame contains {total_players} players.')\n",
    "    \n",
    "    \n",
    "    ## Return final list of Player URLs\n",
    "    return(df_fbref_player_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023f6bd",
   "metadata": {},
   "source": [
    "### Function to get goalkeepers data from FBRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c43a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for scraping a defined season and competition of FBref player data\n",
    "def get_fbref_goalkeeper_stats(lst_league_names, lst_seasons):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to scrape goalkeeper stats from FBref.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ## Define list of league names\n",
    "    league_names_long = lst_league_names\n",
    "    \n",
    "    \n",
    "    ## Define seasons to scrape\n",
    "    seasons = lst_seasons\n",
    "    \n",
    "    ## Scrape information for each player\n",
    "    for season in seasons:\n",
    "\n",
    "        ### Print message\n",
    "        print(f'Scraping started for the {season} season...')\n",
    "\n",
    "        ### Loop through leagues\n",
    "        for league_name_long in league_names_long:\n",
    "            \n",
    "            #### Determine league short name from the league names dictionary\n",
    "            league_name_short = [v for k,v in dict_league_names.items() if k == league_name_long][0]\n",
    "            \n",
    "            #### Save Player URL List (if not already saved)\n",
    "            if not os.path.exists(os.path.join(data_dir_fbref + f'/raw/goalkeeper/{league_name_long}/{season}/fbref_goalkeeper_stats_{league_name_long}_{season}_latest.csv', encoding='utf-8')):\n",
    "\n",
    "                ##### Scraping\n",
    "\n",
    "                ##### Print statement\n",
    "                print(f'Scraping started for goalkeeper stats data for {league_name_long} league for the {season} season...')\n",
    "\n",
    "                ##### Standard stats\n",
    "                print(f'Scraping Standard stats...')\n",
    "                url_std_stats = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fstats%2Fplayers%2F{season}-{league_name_long}&div=div_stats_standard'\n",
    "                df_std_stats = pd.read_html(url_std_stats, header=1)[0]\n",
    "\n",
    "                ##### Goalkeeper stats\n",
    "                print(f'Scraping Goalkeeper stats...')\n",
    "                url_keepers = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fkeepers%2Fplayers%2F{season}-{league_name_long}&div=div_stats_keeper'\n",
    "                df_keepers = pd.read_html(url_keepers, header=1)[0]\n",
    "\n",
    "                ##### Advanced Goalkeeper stats\n",
    "                print(f'Scraping Advanced Goalkeeper stats...')\n",
    "                url_keepers_adv = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fkeepersadv%2Fplayers%2F{season}-{league_name_long}&div=div_stats_keeper_adv'\n",
    "                df_keepers_adv = pd.read_html(url_keepers_adv, header=1)[0]\n",
    "\n",
    "                ##### Playing Time stats\n",
    "                print(f'Scraping Playing Time stats...')\n",
    "                url_playing_time = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fplayingtime%2Fplayers%2F{season}-{league_name_long}&div=div_stats_playing_time'\n",
    "                df_playing_time = pd.read_html(url_playing_time, header=1)[0]\n",
    "\n",
    "                ##### Miscellaneous stats\n",
    "                print(f'Scraping Miscellaneous stats...')\n",
    "                url_misc = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fmisc%2Fplayers%2F{season}-{league_name_long}&div=div_stats_misc'\n",
    "                df_misc = pd.read_html(url_misc, header=1)[0]\n",
    "\n",
    "                ##### Concatenate defined individual DataFrames\n",
    "                \n",
    "                ####### Define DataFrames to be concatenated side-by-side (not all of them)\n",
    "                lst_dfs = [df_keepers, df_keepers_adv]\n",
    "\n",
    "                ###### Concatenate DataFrames side-by-side (indicated in list above)\n",
    "                df_all = pd.concat(lst_dfs, axis=1)\n",
    "\n",
    "                ###### Drop duplicate columns\n",
    "                df_all = df_all.loc[:,~df_all.columns.duplicated()]\n",
    "\n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "                \n",
    "                ##### Left join defined individual DataFrames\n",
    "                \n",
    "                ####### Define join conditions\n",
    "                conditions_join = ['Player', 'Nation', 'Pos', 'Squad', 'Comp']\n",
    "\n",
    "                ###### Left join Standard Stats data\n",
    "                df_all = pd.merge(df_all, df_std_stats, left_on=conditions_join, right_on=conditions_join, how='left')\n",
    "\n",
    "                ###### Remove duplicate columns after join (contain '_y') and remove '_x' suffix from kept columns\n",
    "                df_all = df_all[df_all.columns.drop(list(df_all.filter(regex='_y')))]\n",
    "                df_all.columns = df_all.columns.str.replace('_x','')\n",
    "                \n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "                \n",
    "                ###### Left join Playing Time data\n",
    "                df_all = pd.merge(df_all, df_playing_time, left_on=conditions_join, right_on=conditions_join, how='left')\n",
    "\n",
    "                ###### Remove duplicate columns after join (contain '_y') and remove '_x' suffix from kept columns\n",
    "                df_all = df_all[df_all.columns.drop(list(df_all.filter(regex='_y')))]\n",
    "                df_all.columns = df_all.columns.str.replace('_x','')\n",
    "                \n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "\n",
    "                ###### Left join Misc data\n",
    "                df_all = pd.merge(df_all, df_misc, left_on=conditions_join, right_on=conditions_join, how='left')\n",
    "\n",
    "                ###### Remove duplicate columns after join (contain '_y') and remove '_x' suffix from kept columns\n",
    "                df_all = df_all[df_all.columns.drop(list(df_all.filter(regex='_y')))]\n",
    "                df_all.columns = df_all.columns.str.replace('_x','')\n",
    "                \n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "                \n",
    "                \n",
    "                ##### Engineer DataFrames\n",
    "                \n",
    "                ###### Take first two digits of age - fixes current season issue with extra values\n",
    "                df_all['Age'] = df_all['Age'].astype(str).str[:2]\n",
    "                \n",
    "                ###### Create columns for league code and season\n",
    "                df_all['League Name'] = league_name_long\n",
    "                df_all['League ID'] = league_name_short\n",
    "                df_all['Season'] = season              \n",
    "\n",
    "                ###### Drop duplicates\n",
    "                df_all = df_all.drop_duplicates()\n",
    "\n",
    "                \n",
    "                ##### Save DataFrame\n",
    "                df_all.to_csv(data_dir_fbref + f'/raw/goalkeeper/{league_name_long}/{season}/fbref_goalkeeper_stats_{league_name_long}_{season}_latest.csv', index=None, header=True, encoding='utf-8')        \n",
    "                \n",
    "                ##### Export a copy to the 'archive' subfolder, including the date\n",
    "                #df_all.to_csv(data_dir_fbref + f'/raw/goalkeeper/{league_name_long}/{season}/archive/fbref_goalkeeper_stats_{league_name_long}_{season}_last_updated_{today}.csv', index=None, header=True, encoding='utf-8')        \n",
    "                \n",
    "                \n",
    "                ##### Print statement for league and season\n",
    "                print(f'All Goalkeeper stats data for the {league_name_long} league for {season} season scraped and saved.')\n",
    "             \n",
    "            \n",
    "            #### Load goalkeeper stats data (if already saved)\n",
    "            else:\n",
    "\n",
    "                ##### Print statement\n",
    "                print(f'Goalkeeper stats data for the {league_name_long} league for the {season} season already saved as a CSV file.')         \n",
    "\n",
    "                \n",
    "   \n",
    "    ## Unify individual CSV files as a single DataFrame\n",
    "    \n",
    "    ### Show files in directory\n",
    "    all_files = glob.glob(os.path.join(data_dir_fbref + f'/raw/goalkeeper/*/*/fbref_goalkeeper_stats_*_*_latest.csv'))\n",
    "    \n",
    "    ### Create an empty list of Players URLs\n",
    "    lst_goalkeeper_stats_all = []\n",
    "\n",
    "    ### Loop through list of files and read into temporary DataFrames\n",
    "    for filename in all_files:\n",
    "        df_temp = pd.read_csv(filename, index_col=None, header=0)\n",
    "        lst_goalkeeper_stats_all.append(df_temp)\n",
    "\n",
    "    ### Concatenate the files into a single DataFrame\n",
    "    df_fbref_goalkeeper_stats_all = pd.concat(lst_goalkeeper_stats_all, axis=0, ignore_index=True)\n",
    "    \n",
    "    ### Drop header row of each concatenated  DataFrame (contains 'Rk', 'Rk' column)\n",
    "    df_fbref_goalkeeper_stats_all = df_fbref_goalkeeper_stats_all[~df_fbref_goalkeeper_stats_all['Rk'].str.contains('Rk')]\n",
    "    \n",
    "    ### Drop 'Rk' column\n",
    "    df_fbref_goalkeeper_stats_all = df_fbref_goalkeeper_stats_all.drop(['Rk'], axis=1)\n",
    "    \n",
    "    ### Reset index\n",
    "    #df_fbref_goalkeeper_stats_all = df_fbref_goalkeeper_stats_all.reset_index()\n",
    "    \n",
    "    ### Sort DataFrame\n",
    "    df_fbref_goalkeeper_stats_all = df_fbref_goalkeeper_stats_all.sort_values(['League Name', 'Season', 'Player'], ascending=[True, True, True])\n",
    "\n",
    "    \n",
    "    ## Export DataFrame\n",
    "    \n",
    "    ###\n",
    "    df_fbref_goalkeeper_stats_all.to_csv(data_dir_fbref + f'/raw/goalkeeper/fbref_goalkeeper_stats_combined_latest.csv', index=None, header=True, encoding='utf-8')\n",
    "    \n",
    "    ### Save a copy to archive folder (dated)\n",
    "    #df_fbref_goalkeeper_stats_all.to_csv(data_dir_fbref + f'/raw/goalkeeper/archive/fbref_goalkeeper_stats_combined_last_updated_{today}.csv', index=None, header=True, encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    ## Distinct number of goalkeepers\n",
    "    total_players = df_fbref_goalkeeper_stats_all['Player'].nunique()\n",
    "\n",
    "\n",
    "    ## Print statement\n",
    "    print(f'Goalkeeper stats DataFrame contains {total_players} players.')\n",
    "    \n",
    "    \n",
    "    ## Return final list of Player URLs\n",
    "    return(df_fbref_goalkeeper_stats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a53063c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all columns of pandas DataFrames\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1745b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
